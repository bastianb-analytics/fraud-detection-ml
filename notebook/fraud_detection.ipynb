# Dataset source:
# https://www.kaggle.com/datasets/marusagar/bank-transaction-fraud-detection

# =====================================
# Imports
# =====================================

# Data manipulation
import numpy as np
import pandas as pd

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Model interpretability
import shap

# Machine Learning
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score, roc_curve

# =====================================
# Load dataset
# =====================================

# The dataset is assumed to be in the same directory as this notebook
data = pd.read_csv("Bank_Transaction_Fraud_Detection.csv")

# Quick inspection
data.head()

# =====================================
# Missing Values Check
# =====================================

# We check for missing values to determine whether data cleaning is required
# and to avoid potential statistical bias during the analysis.
data.isna().sum()

# As observed, the dataset contains no missing values,
# so we can proceed with the analysis without additional imputation steps.

# =====================================
# Date and Location Feature Assessment
# =====================================

# The transactions in the dataset occurred in January 2025.
# Therefore, the month and year do not provide additional information
# and can be excluded from the analysis.
data['Transaction_Date'] = pd.to_datetime(data['Transaction_Date'])
data['Day'] = data['Transaction_Date'].dt.day

# A quick inspection shows that all transactions are from India.
data['State'].unique()

# Since all transactions take place in India, the transaction currency
# is consistently INR (Indian Rupees). Therefore, the 'Transaction_Currency'
# column does not add informative value and can be safely removed.

# =====================================
# Frequency Features: Email and Contact
# =====================================

# Some customer emails and contact numbers appear multiple times in the dataset.
# Repeated identifiers may indicate higher transaction activity or potential fraud patterns.
# Therefore, we compute their frequencies and add them as new numerical features.

email_freq = data.groupby('Customer_Email').size()
data['email_freq'] = data['Customer_Email'].map(email_freq)

contact_freq = data.groupby('Customer_Contact').size()
data['contact_freq'] = data['Customer_Contact'].map(contact_freq)

# ============================================================
# Feature Selection, Preprocessing and Model Training
# ============================================================

# Some columns are identifiers or metadata and do not provide
# predictive information for fraud detection.
# These include UUIDs, timestamps, and free-text fields.
# Therefore, they are excluded from the modeling stage.

# Numerical features
num_features = [
    'Transaction_Amount',
    'Account_Balance',
    'Age',
    'email_freq',
    'contact_freq'
]

# Categorical features
cat_features = [
    'Transaction_Type',
    'Transaction_Device',
    'Device_Type',
    'Merchant_Category',
    'Account_Type',
    'Gender',
    'State'
]

# Feature matrix (only selected variables)
X = data[num_features + cat_features]

# Target variable
y = data['Is_Fraud']

# Column-wise preprocessing:
# - Numerical features are passed through unchanged
# - Categorical features are one-hot encoded
preprocess = ColumnTransformer(
    transformers=[
        ('num', 'passthrough', num_features),
        ('cat', OneHotEncoder(
            handle_unknown='ignore',
            min_frequency=0.01,     # group rare categories
            sparse_output=False
        ), cat_features)
    ]
)

# Random Forest model
# Class imbalance is handled using class_weight='balanced'
rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=10,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)

# Full pipeline
model = Pipeline(steps=[
    ('preprocess', preprocess),
    ('classifier', rf)
])

# Train-test split with stratification due to class imbalance
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.30,
    stratify=y,
    random_state=42
)

# Model training
model.fit(X_train, y_train)

# Predictions and evaluation
y_pred = model.predict(X_test)

print(classification_report(y_test, y_pred))

# ============================================================
# Feature Importance Analysis (Random Forest)
# ============================================================

# Extract feature names after preprocessing
feature_names = model.named_steps['preprocess'].get_feature_names_out()

# Extract impurity-based feature importances from Random Forest
importances = model.named_steps['classifier'].feature_importances_

# Create DataFrame with feature importances
feat_imp = (
    pd.DataFrame({
        'feature': feature_names,
        'importance': importances
    })
    .sort_values('importance', ascending=False)
)

# Display top 15 most important features
feat_imp.head(15)

# Plot top 15 feature importances
feat_imp.head(15).plot(
    kind='barh',
    x='feature',
    y='importance',
    figsize=(8, 6),
    legend=False
)

plt.title("Feature Importance – Random Forest (Impurity-Based)")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# Interpretation:
# As observed, 'Account_Balance', 'Transaction_Amount', and 'Age'
# are the dominant variables in reducing node impurity.
#
# Numerical variables tend to dominate impurity-based importance
# measures in Random Forests.
#
# Categorical variables contribute more marginally to overall performance,
# which was evaluated separately using performance-based metrics
# (e.g., ROC-AUC) rather than relying solely on internal feature importances.

# ============================================================
# Fraud Analysis by Bank Branch
# ============================================================

# Analyze the number of transactions per bank branch
# and compare them with the observed fraud cases

banks = pd.crosstab(
    index=data['Bank_Branch'],
    columns=data['Is_Fraud']
)

# Total number of transactions per bank
banks['Total'] = banks.sum(axis=1)
banks = banks.sort_values(by='Total', ascending=False)

# Fraud rate per bank branch
banks['fraud_rate'] = banks[1] / banks['Total']

# Relative fraud risk:
# ratio between each bank's fraud rate and the global average fraud rate
# This measures the relative deviation from normal behavior
banks['relative_risk'] = banks['fraud_rate'] / banks['fraud_rate'].mean()

# Plot banks with the highest relative fraud risk
banks['relative_risk'].sort_values(ascending=False).head(20).plot(
    kind='bar',
    figsize=(12, 5)
)

plt.title("Bank Branches with Highest Relative Fraud Risk")
plt.ylabel("Relative Risk")
plt.xlabel("Bank Branch")
plt.tight_layout()
plt.show()

# ============================================================
# Feature Ablation Study (AUC-based)
# ============================================================

# We evaluate the importance of key numerical features
# by measuring the drop in ROC-AUC when each feature is removed.

features = [
    'Transaction_Amount',
    'Account_Balance',
    'Age'
]

X = data[features]
y = data['Is_Fraud']

# Train-test split preserving class imbalance
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42,
    stratify=y
)

# Baseline model using all features
rf_base = RandomForestClassifier(
    n_estimators=300,
    random_state=42,
    n_jobs=-1,
    class_weight='balanced'
)

rf_base.fit(X_train, y_train)

base_auc = roc_auc_score(
    y_test,
    rf_base.predict_proba(X_test)[:, 1]
)

# Feature ablation loop
results = []

for f in features:
    feats_minus = [x for x in features if x != f]

    rf_tmp = RandomForestClassifier(
        n_estimators=300,
        random_state=42,
        n_jobs=-1,
        class_weight='balanced'
    )

    rf_tmp.fit(X_train[feats_minus], y_train)

    auc = roc_auc_score(
        y_test,
        rf_tmp.predict_proba(X_test[feats_minus])[:, 1]
    )

    results.append({
        'feature_removed': f,
        'auc_without_feature': auc,
        'auc_drop': base_auc - auc
    })

ablation_df = (
    pd.DataFrame(results)
    .sort_values('auc_drop', ascending=False)
)

ablation_df

# Interpretation:
# The results show that fraud prediction in this dataset
# is primarily driven by transaction amount, account balance,
# and customer age.
#
# This confirms that behavioral and financial magnitude features
# carry significantly more predictive power than transaction
# type or device-related variables in this context.

# ============================================================
# SHAP Analysis – Model Explainability
# ============================================================

# We train a dedicated Random Forest model for SHAP analysis
# to understand how each feature contributes to fraud prediction.

rf_shap = RandomForestClassifier(
    n_estimators=300,
    random_state=42,
    n_jobs=-1,
    class_weight='balanced'
)

rf_shap.fit(X_train, y_train)

# Sample a subset of the test data for SHAP visualization
X_shap = X_test.sample(1000, random_state=42)

# Create SHAP explainer (Tree-based models)
explainer = shap.TreeExplainer(rf_shap)

# Compute SHAP values using the new unified API
shap_values = explainer(X_shap)

# SHAP summary plot for the fraud class (class = 1)
shap.summary_plot(
    shap_values[..., 1],
    X_shap,
    plot_type='dot'
)

# Interpretation:
# Most observations are concentrated around the base value,
# indicating that individual features rarely push predictions
# strongly toward the fraud class.
#
# This behavior is consistent with the strong class imbalance (~5% fraud)
# and the high similarity between fraudulent and non-fraudulent transactions.
#
# As a result, the model assigns a dominant negative probability to most cases,
# leading to SHAP contributions clustered near zero and ROC-AUC values
# moderately above random guessing.

# ============================================================
# Risk-Oriented Fraud Scoring Model
# ============================================================

# Instead of producing a strict binary decision,
# we train a probabilistic model that outputs a fraud risk score.
# This approach is better suited for real-world decision systems
# where thresholds can be adjusted based on business constraints.

features = [
    'Transaction_Amount',
    'Account_Balance',
    'Age'
]

X = data[features]
y = data['Is_Fraud']

# Train the final model using the full dataset
pipe = Pipeline(steps=[
    ('model', RandomForestClassifier(
        n_estimators=300,
        random_state=42,
        class_weight='balanced',
        n_jobs=-1
    ))
])

pipe.fit(X, y)

# Fraud risk prediction function
def predict_fraud_risk(model, amount, balance, age):
    """
    Returns the estimated probability of a transaction being fraudulent.
    """
    row = pd.DataFrame([{
        'Transaction_Amount': amount,
        'Account_Balance': balance,
        'Age': age
    }])

    return model.predict_proba(row)[0, 1]

# ============================================================
# Example: Fraud Risk Prediction
# ============================================================

# Using the trained model, we estimate the fraud risk score
# based on transaction amount, remaining account balance, and customer age.
# This score serves as a decision-support indicator rather than
# a definitive fraud classification.

#Example:
p = predict_fraud_risk(
    pipe,
    amount=50_000,
    balance=20_000,
    age=60
)

print(f"Estimated fraud probability: {p:.2%}")


